---
title: "Creación de modelos para Glioblastoma"
output: html_notebook
---

```{r}
library(mlbench)
library(caret)
library(corrplot)
library(e1071)
library(MLmetrics)
library(smotefamily)
library(openxlsx)
library(cvms)
```

Este documento explica el proceso de creación de un modelo basado en Machine Learning (ML) para predecir el estado vital del paciente (vivo/muerto) a los 12 meses para pacientes con Glioblastoma (GBM). Esto se realiza basándose en metadatos de los pacientes y características extraídas de imágenes MRI.

## Cargar datos y librerías
Se cargan los datos y se dividen en datasets de entrenamiento (train) y validación (test). Los datos cargados se corresponden al dataset empleado para la estimación de la curva de supervivencia, por lo que el proceso de EDA y parte del pre-procesamiento ya ha sido llevado a cabo previamente.

```{r load data}
load(file = 'dataset_images_12month_features_completed.Rda')
gbm_dataset <- dataset_images_12month_features_completed
gbm_dataset <- gbm_dataset[, -which(names(gbm_dataset) == 'time_monitored', arr.ind = TRUE)]

# Dividir los datos
set.seed(7)
validationIndex <- createDataPartition(gbm_dataset$vital_status_at_12months_follow_up, p=0.80, list=FALSE)
# Seleccionar el 20% de los datos para la validación
gbm_dataset_v <- gbm_dataset[-validationIndex,]
# Usar el 80% restante para el entrenamiento de los modelos
gbm_dataset <- gbm_dataset[validationIndex,]
```
 
## EDA
Aunque este paso ya ha sido realizado en el análisis de riesgos, se va a analizar el balanceo de los datasets creados y las características de las variables. La variable de clase es el estado vital de los pacientes a los 12 meses (vital_status_at_12months_follow_up) y tiene dos posibles valores: vivo (Living) o muerto (Deceased).

```{r EDA, echo=FALSE}
print('Verificar el balanceo de clase del dataset de training')
cbind(Level_freq=table(gbm_dataset$vital_status_at_12months_follow_up), Level_percent=prop.table(table(gbm_dataset$vital_status_at_12months_follow_up))*100)

print('Verificar el balanceo de clase del dataset de testing')
cbind(Level_freq=table(gbm_dataset_v$vital_status_at_12months_follow_up), Level_percent=prop.table(table(gbm_dataset_v$vital_status_at_12months_follow_up))*100)

print('Verificar datos NA')
missing_val_n <- sum(is.na(gbm_dataset))
missing_val_n
```

Se puede observar que ambos datasets están más o menos balanceados. Los valores NA corresponden a la esperanza de vida de pacientes que siguen vivos a los 12 meses. Para la creación de los modelos y la predicción, se van a quitar las variables tumor_mri_type, edema_mri_type, cause_of_death_at_12months_follow_up y case_id de los datasets.

```{r Remove variables, echo=FALSE}
life_expectancy_index <- which(names(gbm_dataset) == 'life_expectancy', arr.ind = TRUE)
tumor_mri_type_index <- which(names(gbm_dataset) == 'tumor_mri_type', arr.ind = TRUE)
edema_mri_type_index <- which(names(gbm_dataset) == 'edema_mri_type', arr.ind = TRUE)
cause_of_death_index <- which(names(gbm_dataset) == 'cause_of_death_at_12months_follow_up', arr.ind = TRUE)
case_id_index <- which(names(gbm_dataset) == 'case_id', arr.ind = TRUE)
gbm_dataset <- gbm_dataset[, -c(life_expectancy_index, tumor_mri_type_index, edema_mri_type_index, cause_of_death_index, case_id_index)]
gbm_dataset_v <- gbm_dataset_v[, -c(life_expectancy_index, tumor_mri_type_index, edema_mri_type_index, cause_of_death_index, case_id_index)]
```

## Dataset preprocessing

Para la creación de los modelos de predicción se ha decidido crear 3 vistas distintas, las cuales se describen a continuación.

* Dataset con PCA aplicado para la reducción de la dimensionalidad.
* Dataset tal y como se ha aplicado para la creación de la curva de supervivencia.
* Dataset solo con las variables que se han determinado como factores de riesgo en el análisis de la curva de supervivencia.

Se aplicará PCA al dataset de entrenamiento en primer lugar.

```{r}
numeric_vars_index <- c(which(sapply(gbm_dataset, class) == 'numeric', arr.ind = TRUE), which(sapply(gbm_dataset, class) == 'integer', arr.ind = TRUE))
non_numeric_vars_index <- which(sapply(gbm_dataset, class) == 'factor', arr.ind = TRUE)

pr.out.train <- prcomp(gbm_dataset[, numeric_vars_index], scale = TRUE)
biplot(pr.out.train, scale=0)

pr.var <- pr.out.train$sdev^2
pve <- pr.var / sum(pr.var)
pve

par(mfrow=c(1,2))
barplot(pve, xlab='Principal Component', ylab='Proportion of Variance Explained', ylim=c(0,1))
plot(cumsum(pve), xlab='Principal Component', ylab='Cumuative Proportion of Variance Explained', ylim=c(0,1))

preprocessParams <- preProcess(gbm_dataset[, numeric_vars_index], method=c("pca"))
print(preprocessParams)

gbm_dataset_PCA <- pr.out.train$x[,1:preprocessParams$numComp]
gbm_dataset_PCA <- as.data.frame(cbind(gbm_dataset_PCA, gbm_dataset[,non_numeric_vars_index]))
```

También se crea una tercera vista del dataset con los factores de riesgo identificados.

```{r Creación del dataset de los factores de riesgo}
risk_factors <- c("alcohol_consumption", "age", "bmi", "tobacco_smoking_history", "tumor_Hu_3", "edema_glcm_correlation", "tumor_size_in_cm", "height_in_cm", "tumor_ent", "tumor_Hu_2", "tumor_Hu_6", "gender", "tumor_glcm_contrast", "tumor_smoothness")

risk_factor_indexes <- c()
for (i in 1:length(risk_factors)){
  risk_factor_indexes[i] = which(colnames(gbm_dataset) == risk_factors[i], arr.ind = TRUE)
}

gbm_dataset_risk <- gbm_dataset[,risk_factor_indexes]
gbm_dataset_risk$vital_status_at_12months_follow_up <- gbm_dataset$vital_status_at_12months_follow_up
```


## Creación de modelos

Para cada una de las vistas definida se han creado 5 modelos distintos empleando 5 algoritmos (SVM, KNN, Random Forest, Boosting y Regresión Logística). Se ha aplicado la técnica "repeatedcv" para tener más datos para evaluar los algoritmos y así poder realizar una comparación más completa. Todos los algoritmos, menos el de Regresión Logística, han sido modificados para que los parámetros que emplee no sean únicamente los definidos por defecto.


```{r Creación de modelo PCA, warning = FALSE}
control <- trainControl(method="repeatedcv", number = 5, repeats = 3, classProbs = TRUE, summaryFunction = multiClassSummary)

grid <- expand.grid(sigma = c(1:8) * 0.03194379, C = c(1:10)*0.25)
set.seed(7)
fit.svm.PCA <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_PCA, method="svmRadial", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo SVM con el dataset PCA')
print(fit.svm.PCA)

grid <- expand.grid(k = c(2:7)*2 - 1)
set.seed(7)
fit.knn.PCA <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_PCA, method="knn", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo KNN con el dataset PCA')
print(fit.knn.PCA)

grid <- expand.grid(mtry = c(2, 11, 20, c(1:7)*10))
set.seed(7)
fit.rf.PCA <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_PCA, method="rf", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo random forest con el dataset PCA')
print(fit.rf.PCA)

grid <- expand.grid(nrounds = c(1, 200, 400), max_depth = c(2:10),
                    eta = 0.3, gamma = 0,
                    colsample_bytree = 1, min_child_weight = 1,
                    subsample = 1)
set.seed(7)
fit.boost.PCA <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_PCA, method="xgbTree", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo de boosting con el dataset PCA')
print(fit.boost.PCA)

set.seed(7)
fit.logreg.PCA <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_PCA, method="LMT", metric="ROC", trControl=control)
print('Algoritmo de regresión logística con el dataset PCA')
print(fit.logreg.PCA)

```

```{r Creación de modelo sin PCA, warning = FALSE}
control <- trainControl(method="repeatedcv", number = 5, repeats = 3, classProbs = TRUE, summaryFunction = multiClassSummary)

grid <- expand.grid(sigma = c(1:8) * 0.02529123, C = c(1:10)*0.25)
set.seed(7)
fit.svm <- train(vital_status_at_12months_follow_up~., data=gbm_dataset, method="svmRadial", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo SVM con el dataset sin variables correlacionadas')
print(fit.svm)

grid <- expand.grid(k = c(2:7)*2 - 1)
set.seed(7)
fit.knn <- train(vital_status_at_12months_follow_up~., data=gbm_dataset, method="knn", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo KNN con el dataset sin variables correlacionadas')
print(fit.knn)

grid <- expand.grid(mtry = c(2, 17, 33, c(1:7)*10))
set.seed(7)
fit.rf <- train(vital_status_at_12months_follow_up~., data=gbm_dataset, method="rf", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo random forest con el dataset sin variables correlacionadas')
print(fit.rf)


grid <- expand.grid(nrounds = c(1, 200, 400), max_depth = c(2:10),
                    eta = 0.3, gamma = 0,
                    colsample_bytree = 1, min_child_weight = 1,
                    subsample = 1)
set.seed(7)
fit.boost <- train(vital_status_at_12months_follow_up~., data=gbm_dataset, method="xgbTree", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo de boosting con el dataset sin variables correlacionadas')
print(fit.boost)

set.seed(7)
fit.logreg <- train(vital_status_at_12months_follow_up~., data=gbm_dataset, method="LMT", metric="ROC", trControl=control)
print('Algoritmo de regresión logística con el dataset sin variables correlacionadas')
print(fit.logreg)
```

```{r Creación de modelo factores de riesgo, warning = FALSE}
control <- trainControl(method="repeatedcv", number = 5, repeats = 3, classProbs = TRUE, summaryFunction = multiClassSummary)

grid <- expand.grid(sigma = c(1:8) * 0.04736772, C = c(1:10)*0.25)
set.seed(7)
fit.svm.risk <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_risk, method="svmRadial", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo SVM con el dataset de los factores de riesgo')
print(fit.svm.risk)

grid <- expand.grid(k = c(2:7)*2 - 1)
set.seed(7)
fit.knn.risk <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_risk, method="knn", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo KNN con el dataset de los factores de riesgo')
print(fit.knn.risk)

grid <- expand.grid(mtry = c(2, 10, 18, c(1:7)*10))
set.seed(7)
fit.rf.risk <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_risk, method="rf", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo random forest con el dataset de los factores de riesgo')
print(fit.rf.risk)

grid <- expand.grid(nrounds = c(1, 200, 400), max_depth = c(2:10),
                    eta = 0.3, gamma = 0,
                    colsample_bytree = 1, min_child_weight = 1,
                    subsample = 1)
set.seed(7)
fit.boost.risk <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_risk, method="xgbTree", metric="ROC", trControl=control, tuneGrid = grid)
print('Algoritmo de boosting con el dataset de los factores de riesgo')
print(fit.boost.risk)

set.seed(7)
fit.logreg.risk <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_risk, method="LMT", metric="ROC", trControl=control)
print('Algoritmo de regresión logística con el dataset de los factores de riesgo')
print(fit.logreg.risk)
```

## Comparación de los modelos

De todas las métricas disponibles se han seleccionado Accuracy y LogLoss para evaluar la capacidad del modelo para predecir ambos niveles de la variable de clase y obvservar como la métrica es penalizada en el valor del LogLoss. Se eliminan las métricas que contienen algún valor NA.

```{r model comparation}
results <- resamples(list(SVM_PCA=fit.svm.PCA, KNN_PCA=fit.knn.PCA, RF_PCA=fit.rf.PCA, BOOST_PCA=fit.boost.PCA, LMT_PCA=fit.logreg.PCA,
                          SVM_NOCOR=fit.svm, KNN_NOCOR=fit.knn, RF_NOCOR=fit.rf, BOOST_NOCOR=fit.boost, LMT_NOCOR=fit.logreg,
                          SVM_RISK=fit.svm.risk, KNN_RISK=fit.knn.risk, RF_RISK=fit.rf.risk, BOOST_RISK=fit.boost.risk, LMT_RISK=fit.logreg.risk))
ind_na_col <- c(which(names(results$values) == "SVM_PCA~F1", arr.ind = TRUE),
                which(names(results$values) == "KNN_PCA~F1", arr.ind = TRUE),
                which(names(results$values) == "RF_PCA~F1", arr.ind = TRUE),
                which(names(results$values) == "BOOST_PCA~F1", arr.ind = TRUE),
                which(names(results$values) == "LMT_PCA~F1", arr.ind = TRUE),
                which(names(results$values) == "SVM_PCA~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "KNN_PCA~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "RF_PCA~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "BOOST_PCA~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "LMT_PCA~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "SVM_PCA~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "KNN_PCA~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "RF_PCA~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "BOOST_PCA~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "LMT_PCA~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "SVM_PCA~Precision", arr.ind = TRUE),
                which(names(results$values) == "KNN_PCA~Precision", arr.ind = TRUE),
                which(names(results$values) == "RF_PCA~Precision", arr.ind = TRUE),
                which(names(results$values) == "BOOST_PCA~Precision", arr.ind = TRUE),
                which(names(results$values) == "LMT_PCA~Precision", arr.ind = TRUE),
                
                which(names(results$values) == "SVM_NOCOR~F1", arr.ind = TRUE),
                which(names(results$values) == "KNN_NOCOR~F1", arr.ind = TRUE),
                which(names(results$values) == "RF_NOCOR~F1", arr.ind = TRUE),
                which(names(results$values) == "BOOST_NOCOR~F1", arr.ind = TRUE),
                which(names(results$values) == "LMT_NOCOR~F1", arr.ind = TRUE),
                which(names(results$values) == "SVM_NOCOR~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "KNN_NOCOR~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "RF_NOCOR~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "BOOST_NOCOR~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "LMT_NOCOR~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "SVM_NOCOR~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "KNN_NOCOR~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "RF_NOCOR~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "BOOST_NOCOR~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "LMT_NOCOR~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "SVM_NOCOR~Precision", arr.ind = TRUE),
                which(names(results$values) == "KNN_NOCOR~Precision", arr.ind = TRUE),
                which(names(results$values) == "RF_NOCOR~Precision", arr.ind = TRUE),
                which(names(results$values) == "BOOST_NOCOR~Precision", arr.ind = TRUE),
                which(names(results$values) == "LMT_NOCOR~Precision", arr.ind = TRUE),
                
                which(names(results$values) == "SVM_RISK~F1", arr.ind = TRUE),
                which(names(results$values) == "KNN_RISK~F1", arr.ind = TRUE),
                which(names(results$values) == "RF_RISK~F1", arr.ind = TRUE),
                which(names(results$values) == "BOOST_RISK~F1", arr.ind = TRUE),
                which(names(results$values) == "LMT_RISK~F1", arr.ind = TRUE),
                which(names(results$values) == "SVM_RISK~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "KNN_RISK~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "RF_RISK~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "BOOST_RISK~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "LMT_RISK~Neg_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "SVM_RISK~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "KNN_RISK~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "RF_RISK~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "BOOST_RISK~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "LMT_RISK~Pos_Pred_Value", arr.ind = TRUE),
                which(names(results$values) == "SVM_RISK~Precision", arr.ind = TRUE),
                which(names(results$values) == "KNN_RISK~Precision", arr.ind = TRUE),
                which(names(results$values) == "RF_RISK~Precision", arr.ind = TRUE),
                which(names(results$values) == "BOOST_RISK~Precision", arr.ind = TRUE),
                which(names(results$values) == "LMT_RISK~Precision", arr.ind = TRUE))

ind_na_col_metrics <- c(which(results$metrics == "F1", arr.ind = TRUE),
                        which(results$metrics == "Neg_Pred_Value", arr.ind = TRUE),
                        which(results$metrics == "Pos_Pred_Value", arr.ind = TRUE),
                        which(results$metrics == "Precision", arr.ind = TRUE))
results$values <- results$values[, -ind_na_col]
results$metrics <- results$metrics[-ind_na_col_metrics]

print('Summary of the prediction metrics for PCA dataset')
summary(results)

scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results, scales=scales, metric = results$metrics[1], xlim = c(0, 1))
bwplot(results, scales=scales, metric = results$metrics[6], xlim = c(0, 2.1))

diffs <- diff(results)
print('P-value test of the prediction metrics for PCA dataset')
summary_diffs <- summary(diffs)
print(summary_diffs$table$Accuracy)
print(summary_diffs$table$logLoss)
```
Las métricas han sido extraidas a archivos excel para su mejor interpretación debido a la dificultad de comprensión al mostrar grandes matrices.
```{r p-test tables}
write.xlsx(summary_diffs$table$Accuracy, "p-val_accu.xlsx", sheetName = "ACCURACY")
write.xlsx(summary_diffs$table$logLoss, "p-val_logloss.xlsx", sheetName = "LOGLOSS")
```

Con los valores del p-value calculados y teniendo en cuenta los resultados de las dos métricas, se han obtenido las siguientes conclusiones.

* De todos los modelos creados con el dataset en dónde PCA ha sido aplicado, Boosting ha sido el mejor en lo que respecta a Accuracy y a LogLoss. El algoritmo de Regresión Logistica es el que peor rendimiento tiene en lo que corresponde a LogLoss, siendo la diferencia con el resto significativa.

* De los modelos creados con las variables no correlacionadas el mejor en lo que respecta al Accuracy han sido RF y SVM, pero los valores del p-value muestran que la diferencia entre ellos es significativa, siendo SVM el mejor de los dos. SVM es también el algoritmo que mejor funciona respecto a la métrica LogLoss.

* En lo que respecta a los algoritmos en los cuales la base de datos empleada ha sido generada únicamente con los factores de riesgo, KNN y Regresión Logistica son los que mejor rendimiento presentan para la métrica de Accuracy, sin ningún cambio representativo entre ambos modelos, aunque Regresión Logistica es el algoritmo que mayor penalización recibe en la métrica LogLoss.

En general, el valor del Accuracy es bastante bajo para todos los casos, siendo el mejor el algoritmo Boosting para la BD al cual se le ha aplicado PCA. A su vez, éste modelo es el que menos es penalizado mediante la métrica LogLoss. El segundo algoritmo mejor posicionado es el SVM para la BD de PCA. De esta forma, se propone el uso de estos dos modelos para la validación. Dado que PCA puede dificultar la interpretación de los resultados, se ha decidido emplear también el modelo entrenado mediante SVM para la BD de las variables no correlacionadas.

## Modelo final

Se aplica el preprocesamiento al dataset de validación. Se aplica PCA a la BD de validación.

```{r}
gbm_dataset_v_PCA <- predict(pr.out.train, newdata = gbm_dataset_v[,numeric_vars_index])
gbm_dataset_v_PCA <- as.data.frame(gbm_dataset_v_PCA)

gbm_dataset_v_PCA <- gbm_dataset_v_PCA[,1:preprocessParams$numComp]
gbm_dataset_v_PCA <- as.data.frame(cbind(gbm_dataset_v_PCA, gbm_dataset_v[,non_numeric_vars_index]))
```

Ahora los modelos seleccionados se entrenan con todos los datos de training disponibles y empleando los parámetros del mejor resultado obtenido.

```{r}
control <- trainControl(method="none", classProbs = TRUE, summaryFunction = multiClassSummary)

# PCA BOOST
grid <- expand.grid(nrounds = fit.boost.PCA$bestTune$nrounds,
                    max_depth = fit.boost.PCA$bestTune$max_depth,
                    eta = fit.boost.PCA$bestTune$eta,
                    gamma = fit.boost.PCA$bestTune$gamma,
                    colsample_bytree = fit.boost.PCA$bestTune$colsample_bytree,
                    min_child_weight = fit.boost.PCA$bestTune$min_child_weight,
                    subsample = fit.boost.PCA$bestTune$subsample)
set.seed(7)
model.boost.PCA <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_PCA, method="xgbTree", metric="Roc", trControl=control, tuneGrid = grid)

# PCA SVM
grid <- expand.grid(C = fit.svm.PCA$bestTune$C,
                    sigma = fit.svm.PCA$bestTune$sigma)
set.seed(7)
model.svm.PCA <- train(vital_status_at_12months_follow_up~., data=gbm_dataset_PCA, method="svmRadial", metric="Roc", trControl=control, tuneGrid = grid)

# NOCOR SVM
grid <- expand.grid(C = fit.svm$bestTune$C, sigma = fit.svm$bestTune$sigma)
set.seed(7)
model.svm <- train(vital_status_at_12months_follow_up~., data=gbm_dataset, method="svmRadial", metric="ROC", trControl=control, tuneGrid = grid)


```

## Validación del modelo seleccionado

```{r}
test_pred <- predict(model.boost.PCA, newdata = gbm_dataset_v_PCA)
confusionMatrix.Boost.PCA <- confusionMatrix(table(test_pred, gbm_dataset_v_PCA$vital_status_at_12months_follow_up))
print(confusionMatrix.Boost.PCA)
plot_confusion_matrix(confusion_matrix(targets = gbm_dataset_v_PCA$vital_status_at_12months_follow_up, predictions = test_pred))
```

```{r}
test_pred <- predict(model.svm.PCA, newdata = gbm_dataset_v_PCA)
confusionMatrix.svm.PCA <- confusionMatrix(table(test_pred, gbm_dataset_v_PCA$vital_status_at_12months_follow_up))
print(confusionMatrix.svm.PCA)
plot_confusion_matrix(confusion_matrix(targets = gbm_dataset_v_PCA$vital_status_at_12months_follow_up, predictions = test_pred))
```

```{r}
test_pred <- predict(model.svm, newdata = gbm_dataset_v)
confusionMatrix.svm <- confusionMatrix(table(test_pred, gbm_dataset_v$vital_status_at_12months_follow_up))
print(confusionMatrix.svm)
plot_confusion_matrix(confusion_matrix(targets = gbm_dataset_v$vital_status_at_12months_follow_up, predictions = test_pred))
```

## Conclusiones

Observando los resultados obtenidos en la validación de los modelos, el algoritmo que mejor funciona se corresponde al Boosting con el dataset dónde a las variables se les aplica PCA, con un Accuracy de 0.67. Los otros modelos no son capaces de predecir correctamente a los pacientes que han muerto a los 12 meses del diagnóstico.

Con esto podemos concluir que o las características extraidas no son suficientemente representativas o que los pacientes disponibles no son suficientes para entrenar un modelo fiable para la predicción de la supervivencia de los pacientes a 12 meses del diagnóstico.
